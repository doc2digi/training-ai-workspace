{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LCzoheJKW8X"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers datasets==3.2.0 openai lancedb lance FlagEmbedding \"tantivy>=0.20.1\" -qq\n",
        "\n",
        "# NOTE: If there is an import error, restart and run the notebook again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP6d6JUShgqo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import lancedb\n",
        "import re\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "import lance\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import lancedb\n",
        "import openai\n",
        "from lancedb.embeddings import get_registry\n",
        "from lancedb.pydantic import LanceModel, Vector\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-....\"\n",
        "\n",
        "\n",
        "embeddings = get_registry().get(\"openai\").create()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eKRYd2F7v5n"
      },
      "source": [
        "# Load `Chunks` of data from [BeIR Dataset](https://huggingface.co/datasets/BeIR/scidocs)\n",
        "\n",
        "Note: This is a dataset built specially for retrieval tasks to see how good your search is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ezDr7suAf_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import config\n",
        "\n",
        "\n",
        "queries = load_dataset(\"BeIR/scidocs\", \"queries\")[\"queries\"].to_pandas()\n",
        "full_docs = (\n",
        "    load_dataset(\"BeIR/scidocs\", \"corpus\")[\"corpus\"].to_pandas().dropna(subset=\"text\")\n",
        ")\n",
        "\n",
        "docs = full_docs.head(64)  # just random samples for faster embed demo\n",
        "docs[\"num_words\"] = docs[\"text\"].apply(\n",
        "    lambda x: len(x.split())\n",
        ")  # Insert some Metadata for a more \"HYBRID\" search\n",
        "docs.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJf8xZmX8VJC"
      },
      "source": [
        "# Build New Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkhFiOZAwVWw"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aljyqpUiViE"
      },
      "outputs": [],
      "source": [
        "class Documents(LanceModel):\n",
        "    vector: Vector(embeddings.ndims()) = embeddings.VectorField()\n",
        "    text: str = embeddings.SourceField()\n",
        "    title: str\n",
        "    num_words: int\n",
        "\n",
        "\n",
        "data = docs.apply(\n",
        "    lambda row: {\n",
        "        \"title\": row[\"title\"],\n",
        "        \"text\": row[\"text\"],\n",
        "        \"num_words\": row[\"num_words\"],\n",
        "    },\n",
        "    axis=1,\n",
        ").values.tolist()\n",
        "\n",
        "db = lancedb.connect(\"./db\")\n",
        "table = db.create_table(\"documents\", schema=Documents)\n",
        "\n",
        "table.add(data)  # ingest docs with auto-vectorization\n",
        "table.create_fts_index(\"text\")  # Create a fts index before the hybrid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS-soek-yYm4"
      },
      "outputs": [],
      "source": [
        "table.search(\n",
        "    \"To confuse the AI and DNN embedding, let's put random terms from other sentences- automation training test memory?\",\n",
        "    query_type=\"fts\",\n",
        ").limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wo7nfR0yhk7"
      },
      "outputs": [],
      "source": [
        "table.search(\n",
        "    \"To confuse the AI and DNN embedding, let's put random terms from other sentences- automation training test memory?\",\n",
        "    query_type=\"vector\",\n",
        ").limit(10).to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_AH1IxlFPn-"
      },
      "source": [
        "## Perform inbuilt Hybrid Search\n",
        "They have some off the shelf functionalities and a way to implement the custom Re-Ranking and Filtering Function here [Implement Custom Rerankers](https://lancedb.github.io/lancedb/hybrid_search/#building-custom-rerankers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se27vipkFSzf"
      },
      "outputs": [],
      "source": [
        "from lancedb.rerankers import LinearCombinationReranker\n",
        "\n",
        "reranker = LinearCombinationReranker(\n",
        "    weight=0.7\n",
        ")  # Weight = 0 Means pure Text Search (BM-25) and 1 means pure Sementic (Vector) Search\n",
        "\n",
        "table.search(\n",
        "    \"To confuse the AI and DNN embedding, let's put random terms from other sentences- automation training test memory?\",\n",
        "    query_type=\"hybrid\",\n",
        ").rerank(reranker=reranker).limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw5OecIjE3IB"
      },
      "source": [
        "## Build custom Filtering Function\n",
        "\n",
        "By passing the `pandas.query` style, filtering, we will do the following 2 things:\n",
        "\n",
        "1. Remove all the rows which contain a specific term, in out case, `\"dual-band\"`\n",
        "2. Keep only the rows which have `num_words > 100`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfMIXT2vE9yv"
      },
      "outputs": [],
      "source": [
        "from typing import List, Union\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "\n",
        "\n",
        "class MofidifiedLinearReranker(LinearCombinationReranker):\n",
        "    def __init__(self, filters: Union[str, List[str]], **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        filters = filters if isinstance(filters, list) else [filters]\n",
        "        self.filters = filters\n",
        "\n",
        "    def rerank_hybrid(\n",
        "        self, query: str, vector_results: pa.Table, fts_results: pa.Table\n",
        "    ) -> pa.Table:\n",
        "        combined_result = super().rerank_hybrid(query, vector_results, fts_results)\n",
        "        df = combined_result.to_pandas()\n",
        "        for filter in self.filters:\n",
        "            df = df.query(\n",
        "                \"(not text.str.contains(@filter)) & (num_words > 150) \"\n",
        "            )  # THIS is where you implement your filters. You can hard code or pass dynamically too\n",
        "\n",
        "        return pa.Table.from_pandas(df)\n",
        "\n",
        "\n",
        "modified_reranker = MofidifiedLinearReranker(filters=[\"dual-band\"])\n",
        "\n",
        "table.search(\n",
        "    \"To confuse the AI and DNN embedding, let's put random terms from other sentences- automation training test memory?\",\n",
        "    query_type=\"hybrid\",\n",
        ").rerank(reranker=modified_reranker).limit(7).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_yb6WAqLQwU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}